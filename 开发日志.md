# 炼丹蓝图 开发日志

> 这份文档记录了整个项目从零开始的开发过程，包括每一步的想法、决策和具体操作。
>
> **文档用途：**
> - 梳理开发思路，让自己想清楚再动手
> - 方便团队成员了解项目进度和变更原因
> - 作为个人学习和成长的记录

---

## 一、开发原则

开发过程中遵循的核心原则：

| 原则 | 说明 |
|------|------|
| **KISS** | 保持简单，别搞复杂 |
| **MVP** | 先做核心功能，别一开始就想做大而全 |
| **DRY** | 不要重复自己，能复用就复用 |
| **YAGNI** | 用不到的功能别提前做 |

**个人补充：**
- 代码要让人看得懂，别为了炫技写得很绕
- AI可以帮忙补全代码，但别让AI一次性生成大段代码
- 注释要写大白话，别写得跟论文一样

## 二、项目目标

做一个 **AI模型架构可视化设计工具**，就像 Scratch 那样拖拖拽拽就能搭建模型。

**想解决的问题：**
- 不会写代码的人也能搭建AI模型
- 研发人员可以快速验证架构想法
- 降低AI架构设计的门槛

## 三、技术栈

| 类型 | 技术 |
|------|------|
| 前端框架 | React |
| 可视化库 | React Flow |
| UI组件库 | heroUI |
| 构建工具 | Vite |
| 前端语言 | JavaScript |
| 后端语言 | Python |
| ML框架 | PyTorch |

## 四、开发计划

### 前端（已完成）

| 阶段 | 任务 | 状态 |
|------|------|------|
| 1 | 搭建基础环境，接入 React Flow | ✅ 完成 |
| 2 | 封装通用节点组件 | ✅ 完成 |
| 3 | 实现类似 Scratch 的交互操作 | ✅ 完成 |

### 后端（当前开发）

| 阶段 | 任务 |
|------|------|
| 1 | 节点定义系统：用修饰器定义节点，导出配置给前端 |
| 2 | 执行引擎：解析蓝图结构，自动构建计算图 |
| 3 | 验证评估：测试数据流通性，跑分 |

### 前后端通信（已完成）

| 阶段 | 任务 | 状态 |
|------|------|------|
| 1 | 架构下发：前端把模型架构发给后端执行 | ✅ 完成 |
| 2 | 结果反馈：后端执行结果实时同步到前端 | ✅ 完成 |

---

## 五、开发日志

> 下面是实际开发过程的流水账记录，按时间顺序写的。

---

### Step 1：创建项目

我执行了uv init命令，创建了一个新的Python项目。
配置了清华镜像源，加速了依赖安装。
安装了websockets和pytorch库，准备开始开发。

### Step 2：面向理解的架构重构 (Readable & Modular)

为了让项目更加符合人类直觉，我按照“面向理解编程”的原则对代码进行了深度重构：

1. **代码风格：每行必注**：
   - 对 `engine.py`、`registry.py` 和 `loader.py` 进行了重写。
   - 实现了“每行代码尾随注释”，确保逻辑连续性，像 Scratch 一样易于阅读。

2. **逻辑解耦与模块化**：
   - **`engine.py`**：将复杂的执行逻辑拆分为 `_get_execution_order` (排序)、`_collect_inputs` (收集)、`_get_or_build_layer` (构建) 和 `_run_compute` (计算) 等独立步骤。
   - **`registry.py`**：将配置管理与前端导出逻辑分离，增加了类型推断和格式转换的私有方法。
   - **`loader.py`**：简化了动态加载逻辑，使其更加健壮。

3. **健壮性提升**：
   - 修复了 `input` 节点数据透传的逻辑漏洞。
   - 增加了对 PyTorch 标准层（`nn.Module`）的自动适配，支持字典输入与张量输入的自动转换。

### Step 3：端到端测试验证

为了确保重构后的系统依然正确，我执行了完整的回归测试：

1. **测试蓝图 ([`test_blueprint.json`](test_blueprint.json))**：
   - 模拟 MLP 链路：`Input` -> `Linear` -> `ReLU` -> `Linear` -> `Output`。

2. **测试结果**：
   - 运行 `python test_engine.py` 成功跑通。
   - 数据流：`(1, 10) -> (1, 20) -> (1, 20) -> (1, 5)`。
   - 验证了重构后的引擎在保持高可读性的同时，逻辑完全正确。

### Step 4：前后端 WebSocket 通信实现

为了实现前后端对接，我完成了以下开发工作：

1. **新增 WebSocket 服务器模块 ([`ws_server.py`](ws_server.py))**：
   - 基于 `websockets` 库实现异步WebSocket服务器
   - 支持多客户端并发连接
   - 实现了完整的JSON消息通信协议

2. **通信协议设计**：
   - `get_registry`：前端请求获取节点注册表
   - `run_blueprint`：前端发送蓝图给后端执行
   - `node_result`：后端实时推送每个节点的执行结果
   - `execution_complete`：后端通知蓝图执行完成
   - `error`：错误信息响应

3. **引擎回调机制 ([`engine.py`](engine.py))**：
   - 新增 `execute_with_callback` 异步方法
   - 每个节点执行完成后自动调用回调函数
   - 支持实时向前端推送节点执行状态

4. **主程序改造 ([`main.py`](main.py))**：
   - 集成WebSocket服务器启动逻辑
   - 支持命令行参数配置（--host, --port）
   - 默认监听地址：`ws://localhost:8765`

5. **测试客户端 ([`test_ws_client.py`](test_ws_client.py))**：
   - 用于测试WebSocket通信功能
   - 演示完整的请求-响应流程

6. **启动方式**：
   ```bash
   # 启动后端服务器
   uv run python main.py

   # 运行测试客户端（另开一个终端）
   uv run python test_ws_client.py
   ```

### Step 5：节点库扩展

为了支持更复杂的神经网络架构，我扩展了节点库：

1. **神经网络层节点 ([`nodes/layers.py`](nodes/layers.py))**：
   - `Linear`：全连接层
   - `Conv2d`：二维卷积层
   - `BatchNorm2d`：批归一化层
   - `Dropout`：随机失活层
   - `MaxPool2d`：最大池化层
   - `AvgPool2d`：平均池化层
   - `Flatten`：展平层
   - `LSTM`：长短期记忆网络
   - `Embedding`：嵌入层

2. **激活函数节点 ([`nodes/activations.py`](nodes/activations.py))**：
   - `ReLU`、`Sigmoid`、`Tanh`
   - `LeakyReLU`、`Softmax`
   - `GELU`、`SiLU/Swish`

3. **损失函数节点 ([`nodes/losses.py`](nodes/losses.py))**：
   - `CrossEntropyLoss`：交叉熵损失
   - `MSELoss`：均方误差损失
   - `L1Loss`：L1损失
   - `BCELoss`：二元交叉熵损失
   - `BCEWithLogitsLoss`：带Logits的BCE
   - `NLLLoss`：负对数似然损失

### Step 6：引擎健壮性重构

为了提升代码健壮性和可维护性，进行了以下重构：

1. **工具函数模块 ([`utils.py`](utils.py))**：
   - `extract_single_input`：智能提取单输入张量，自动处理端口名不匹配
   - `extract_multi_input`：提取多输入张量
   - `safe_tensor_operation`：安全执行张量操作
   - `ensure_tensor`：确保值为张量格式
   - `get_shape`：安全获取张量形状
   - `serialize_tensor` / `deserialize_tensor`：张量序列化/反序列化

2. **引擎输入处理统一 ([`engine.py`](engine.py) `_run_compute`)**：
   - 无输入节点：直接调用 `compute(None, layer)`
   - 单输入 + nn.Module：引擎直接调用 `layer(x)`
   - 单输入 + 非 nn.Module：引擎解包为张量后传给 `compute(x, layer)`
   - 多输入：引擎传入完整字典，`compute(inputs, layer)` 自行处理

3. **节点定义简化**：
   - 单输入节点的 compute 函数统一使用 `def compute(x, layer)` 签名
   - 引擎负责所有输入格式转换，节点只需专注于计算逻辑

4. **MLP 端到端测试 ([`test_mlp.py`](test_mlp.py))**：
   - 8节点完整MLP网络测试
   - 验证：Input → Linear → ReLU → Linear → ReLU → Linear → Softmax → Output
   - 测试通过，概率分布和为1.0

