# 炼丹蓝图后端代码修改文档

## 📋 文档说明

本文档面向项目接手者，使用大白话详细讲解每个代码文件的核心逻辑、设计思路和常见误区。目标是让新手也能快速理解代码结构，避免踩坑。

## 🏗️ 项目整体架构

### 核心概念
- **蓝图（Blueprint）**: 一个JSON配置文件，描述了整个神经网络的节点连接关系
- **节点（Node）**: 神经网络中的基本操作单元（如线性层、激活函数等）
- **执行引擎（Engine）**: 负责按照拓扑顺序执行蓝图中的节点
- **注册表（Registry）**: 管理所有可用节点的定义和配置

### 文件结构
```
backend/
├── engine.py           # 核心执行引擎
├── context.py          # 执行上下文管理
├── registry.py         # 节点注册表管理
├── loader.py           # 动态加载节点模块
├── decorators.py       # @node和@category装饰器
├── nodes/              # 节点定义目录
│   ├── base.py        # 基础节点（输入、输出、常量等）
│   ├── layers.py      # 神经网络层
│   ├── activations.py # 激活函数
│   └── ...
└── utils/              # 工具模块
    ├── graph.py       # 图算法（拓扑排序等）
    ├── tensor.py      # 张量处理工具
    └── validation.py  # 数据验证和类型转换
```

## 🔍 核心文件详解

### 1. engine.py - 执行引擎（项目心脏）

#### 核心功能
这个文件是整个项目的发动机，负责读取蓝图配置，按照正确的顺序执行所有节点计算。

#### 主要函数详解

##### `run(blueprint, inputs, on_progress)` - 主入口函数
```python
def run(blueprint: Dict[str, Any], inputs: Dict[str, Any], on_progress: Optional[Callable] = None) -> Dict[str, Any]:
```

**大白话解释**：
想象你在做一道复杂的菜，blueprint就是菜谱，inputs是你准备的食材，这个函数就是按照菜谱一步步做菜的过程。

**执行流程**：
1. **加载节点定义** - 确保所有"厨具"（节点）都已准备好
2. **创建执行环境** - 准备"厨房"（上下文）
3. **解析蓝图** - 读取"菜谱"，搞清楚有哪些"步骤"（节点）
4. **拓扑排序** - 确定"做菜顺序"，确保先切菜再炒菜
5. **预构建层** - 提前准备好需要复用的"工具"（如神经网络层）
6. **执行节点** - 按顺序执行每个"步骤"

**⚠️ 常见误区**：
- ❌ 以为所有错误都会在这里抛出 → 实际上很多错误在节点执行时才暴露
- ❌ 忽略拓扑排序的重要性 → 节点执行顺序错误会导致数据未准备好

##### `execute_node(node_id, node_data, context, edges)` - 单个节点执行

**大白话解释**：
这就是执行单个"做菜步骤"的函数，比如"切洋葱"这个步骤。

**关键逻辑**：
1. **获取节点定义** - 搞清楚这个步骤需要什么工具
2. **收集输入数据** - 准备这个步骤需要的"食材"
3. **执行计算** - 真正开始"切菜"
4. **处理输出** - 把切好的菜装盘，准备给下一个步骤用

**⚠️ 常见误区**：
- ❌ 忽略输入检查 → 可能导致None值传递，引发后续错误
- ❌ 忘记处理输出格式 → 下游节点可能无法正确接收数据

##### `_run_compute(compute_func, layer, inputs, node_type, node_def)` - 计算执行策略

**大白话解释**：
这个函数决定"怎么使用工具"，不同的工具（节点类型）有不同的使用方法。

**四种执行策略**：
1. **无输入节点** → 直接调用`compute(None, layer)`
2. **单输入+nn.Module** → 直接`layer(x)`，像使用PyTorch层一样
3. **单输入+其他** → 调用`compute(x, layer)`，自定义计算逻辑
4. **多输入** → 调用`compute(inputs, layer)`，处理多个输入

**⚠️ 常见误区**：
- ❌ 混淆执行策略 → 用错策略会导致计算错误或性能低下
- ❌ 忽略layer参数 → 有些计算需要layer参与，不能省略

### 2. context.py - 执行上下文（项目记忆）

#### 核心功能
这个文件是项目的"记忆系统"，记录执行过程中的所有中间结果和状态。

#### 主要功能详解

##### `ExecutionContext`类 - 执行环境管理器

**大白话解释**：
想象这是一个"厨房记事本"，记录：
- 每个"步骤"做完后的结果（results）
- 准备好的"工具"放在哪里（layers）
- 最初拿进来的"食材"是什么（inputs）

**三个核心存储**：
```python
self.results: Dict[str, Dict[str, Any]] = {}  # 节点输出结果
def store_result(self, node_id: str, output_dict: Dict[str, Any]):
    self.results[node_id] = output_dict  # 记录"步骤"结果
```

```python
self.layers: Dict[str, Any] = {}  # 缓存的层实例
def store_layer(self, node_id: str, layer: Any):
    self.layers[node_id] = layer  # 记录"工具"位置
```

```python
self.inputs: Dict[str, Any] = inputs or {}  # 初始输入数据
def get_initial_input(self, node_id: str):
    return self.inputs.get(node_id)  # 获取"原始食材"
```

**⚠️ 常见误区**：
- ❌ 混淆results和layers → results存计算结果，layers存可复用的层实例
- ❌ 忽略输入节点处理 → 输入节点的数据来自初始inputs，不是上游节点

##### `get_inputs(node_id, edges)` - 输入数据收集

**大白话解释**：
这个函数像"传菜员"，根据"订单"（edges）把上一个"厨师"做好的菜传给下一个厨师。

**工作流程**：
1. 遍历所有"订单"（edges）
2. 找到目标是自己（node_id）的订单
3. 从"已完成的订单"（results）中找到源节点的菜
4. 按正确的"餐桌号"（端口）装盘

**⚠️ 常见误区**：
- ❌ 忽略端口匹配 → sourceHandle和targetHandle必须正确对应
- ❌ 忘记处理非字典输出 → 有些节点直接返回值，不是字典

### 3. registry.py - 节点注册表（项目字典）

#### 核心功能
这个文件是项目的"大词典"，记录了所有可用的"做菜步骤"（节点）的定义和配置。

#### 主要功能详解

##### `register_node()` - 节点注册

**大白话解释**：
这就是给每个"做菜步骤"写说明书，告诉系统：
- 这个步骤叫什么名字（id）
- 属于哪类菜（category）
- 需要什么食材（inputs）
- 做出来什么菜（outputs）
- 需要什么调料（params）
- 具体怎么做（func）

**⚠️ 常见误区**：
- ❌ 重复注册相同ID → 会覆盖之前的定义，导致意外行为
- ❌ 忘记注册分类 → 节点会变成"无分类"，前端显示异常

##### `get_all_for_frontend()` - 前端数据导出

**大白话解释**：
把"大词典"翻译成前端能看懂的格式，就像给外国厨师翻译中文菜谱。

**数据转换**：
- 分类信息 → 前端下拉菜单
- 节点定义 → 节点库面板
- 参数配置 → 属性编辑器

**⚠️ 常见误区**：
- ❌ 忽略参数类型推断 → 前端无法正确显示输入控件
- ❌ 忘记处理默认值 → 用户看不到预设参数

### 4. loader.py - 动态加载器（项目自动发现）

#### 核心功能
这个文件是项目的"自动发现系统"，能自动找到并加载所有节点定义文件。

#### 主要功能详解

##### `load_all_nodes(nodes_dir)` - 批量加载

**大白话解释**：
这就像"自动扫描厨房"，找出所有可用的"菜谱文件"（节点定义）。

**工作流程**：
1. **重置注册表** - 清空之前的"菜谱"
2. **验证目录** - 确认"菜谱柜"存在
3. **遍历文件** - 扫描所有.py文件
4. **动态导入** - 读取每个"菜谱文件"
5. **装饰器注册** - 文件中的`@node`装饰器自动注册节点

**⚠️ 常见误区**：
- ❌ 文件命名不规范 → 以下划线开头的文件会被忽略
- ❌ 循环导入问题 → 节点文件中避免导入loader模块

##### `_load_module_safe()` - 安全加载

**大白话解释**：
这就是"安全试吃员"，即使某个"菜谱"有问题，也不会影响其他菜谱的加载。

**错误处理**：
- 文件不存在 → 记录警告，继续加载
- 语法错误 → 记录错误，跳过该文件
- 导入错误 → 不影响其他文件加载

**⚠️ 常见误区**：
- ❌ 忽略加载错误 → 可能导致节点缺失但无提示
- ❌ 频繁重新加载 → 影响性能，开发时才有必要

### 5. decorators.py - 装饰器（项目声明系统）

#### 核心功能
这个文件提供`@category`和`@node`装饰器，让节点定义变得简单直观。

#### 主要功能详解

##### `@category`装饰器 - 分类定义

**大白话解释**：
这就是"菜系标签"，告诉系统这是川菜、粤菜还是湘菜。

**使用方式**：
```python
@category(id="basic", label="基础", color="#8B92E5")
def basic_category():
    pass  # 函数体可以为空，装饰器会自动注册
```

**⚠️ 常见误区**：
- ❌ ID重复 → 会覆盖之前的分类定义
- ❌ 忘记设置当前分类 → 后续节点会变成"无分类"

##### `@node`装饰器 - 节点定义

**大白话解释**：
这就是"菜谱模板"，标准化地描述一个"做菜步骤"。

**完整示例**：
```python
@node(
    id="linear",           # 节点ID（唯一标识）
    label="全连接层",        # 显示名称
    category="layers",     # 所属分类
    inputs=["x"],          # 输入端口
    outputs=["out"],       # 输出端口  
    params={"in_features": 128, "out_features": 64}  # 参数默认值
)
def linear_layer():
    # 必须返回 (infer, build, compute) 三元组
    def infer(input_shapes, params):
        # 形状推断：告诉系统输出张量的形状
        return {"out": [None, params["out_features"]]}
    
    def build(input_shapes, params):
        # 构建层实例：创建可复用的PyTorch层
        return torch.nn.Linear(params["in_features"], params["out_features"])
    
    def compute(x, layer):
        # 执行计算：真正的前向传播逻辑
        return layer(x)
    
    return infer, build, compute
```

**⚠️ 常见误区**：
- ❌ 忘记返回三元组 → 引擎无法正确执行节点
- ❌ infer函数错误 → 形状推断错误影响后续节点构建
- ❌ build函数耗时 → 应该在compute中处理复杂逻辑

### 6. utils/graph.py - 图算法工具（项目导航）

#### 核心功能
这个文件提供图算法，确保节点按照正确的依赖顺序执行。

#### 主要功能详解

##### `topological_sort()` - 拓扑排序

**大白话解释**：
这就是"做菜顺序规划器"，确保先切菜再炒菜，不会让人先做炒菜再切菜。

**算法原理（Kahn算法）**：
1. **统计入度** - 计算每个"步骤"依赖多少个前置步骤
2. **找起点** - 找出不依赖其他步骤的"起点"
3. **依次处理** - 每完成一个步骤，就减少后续步骤的依赖数
4. **检测循环** - 如果发现还有步骤没做但找不到起点，说明有循环依赖

**⚠️ 常见误区**：
- ❌ 忽略循环依赖检测 → 可能导致死循环或错误结果
- ❌ 假设顺序固定 → 拓扑排序结果可能因实现不同而变化

##### `get_node_inputs()` - 输入收集

**大白话解释**：
这就是"配菜员"，根据"订单"把需要的"食材"准备好。

**工作流程**：
1. 遍历所有"订单"（edges）
2. 找到目标节点的订单
3. 从"已完成菜品"（results）中找到源数据
4. 按正确的"装盘方式"（端口）组织数据

**⚠️ 常见误区**：
- ❌ 忽略端口名称 → 可能导致数据传错位置
- ❌ 不处理缺失数据 → 可能传递None值导致错误

## 🚨 常见开发误区与解决方案

### 1. 节点定义相关

#### ❌ 误区：节点函数忘记返回三元组
```python
# 错误示例
@node(id="bad", label="错误节点")
def bad_node():
    def compute(x):
        return x * 2
    # 忘记返回 (infer, build, compute)
    return compute
```

#### ✅ 正确做法：
```python
@node(id="good", label="正确节点")
def good_node():
    def infer(input_shapes, params):
        return {"out": input_shapes.get("x")}
    
    def build(input_shapes, params):
        return None  # 不需要可复用层
    
    def compute(x, layer):
        return x * 2
    
    return infer, build, compute  # 必须返回三元组
```

### 2. 形状推断相关

#### ❌ 误区：infer函数返回错误的形状
```python
# 错误示例 - 没有考虑batch维度
def infer(input_shapes, params):
    # 假设输入是 [batch, features]，但只返回features
    return {"out": [params["out_features"]]}  # 错误！丢失了batch维度
```

#### ✅ 正确做法：
```python
def infer(input_shapes, params):
    # 正确处理：保留batch维度，只改变特征维度
    batch_size = input_shapes.get("x", [None, None])[0]  # 获取batch大小
    return {"out": [batch_size, params["out_features"]]}
```

### 3. 输入输出处理

#### ❌ 误区：不处理多种输入格式
```python
# 错误示例 - 只处理字典输入
def compute(x, layer):
    # 如果x不是字典，这里会出错
    return layer(x["input"])
```

#### ✅ 正确做法：
```python
def compute(x, layer):
    # 智能处理不同输入格式
    if isinstance(x, dict):
        # 多输入情况
        input_data = x.get("input", list(x.values())[0])
    else:
        # 单输入情况
        input_data = x
    return layer(input_data)
```

### 4. 错误处理

#### ❌ 误区：忽略异常处理
```python
# 错误示例 - 没有异常处理
def build(input_shapes, params):
    # 如果参数缺失，这里会抛出KeyError
    return torch.nn.Linear(params["in_features"], params["out_features"])
```

#### ✅ 正确做法：
```python
def build(input_shapes, params):
    # 提供默认值，优雅处理缺失参数
    in_features = params.get("in_features", 128)
    out_features = params.get("out_features", 64)
    
    # 参数验证
    if in_features <= 0 or out_features <= 0:
        raise ValueError(f"特征数必须为正数: in_features={in_features}, out_features={out_features}")
    
    return torch.nn.Linear(in_features, out_features)
```

### 5. 性能优化

#### ❌ 误区：在compute中做耗时操作
```python
# 错误示例 - 在compute中创建大矩阵
def compute(x, layer):
    # 每次计算都创建新的大矩阵，非常耗时
    large_matrix = torch.randn(10000, 10000)
    return torch.matmul(x, large_matrix)
```

#### ✅ 正确做法：
```python
def build(input_shapes, params):
    # 在build阶段创建可复用的矩阵
    large_matrix = torch.randn(10000, 10000)
    return large_matrix

def compute(x, layer):
    # 直接使用预构建的矩阵
    return torch.matmul(x, layer)
```

## 🔧 调试技巧

### 1. 节点调试

#### 使用调试节点
```python
# 在关键位置插入调试节点
@node(id="debug", label="调试输出", inputs=["x"], outputs=["out"])
def debug_node():
    def compute(x, layer):
        print(f"🔍 调试信息: shape={x.shape if hasattr(x, 'shape') else 'N/A'}")
        print(f"   数据类型: {x.dtype if hasattr(x, 'dtype') else type(x)}")
        print(f"   数值范围: [{x.min():.3f}, {x.max():.3f}]")
        return x  # 透传数据，不影响流程
    return infer, build, compute
```

### 2. 数据流跟踪

#### 打印执行路径
```python
# 在engine.py中添加调试信息
def execute_node(node_id, node_data, context, edges):
    print(f"\n🎯 执行节点: {node_id}")
    print(f"   节点类型: {_get_node_type(node_data)}")
    
    inputs = context.get_inputs(node_id, edges)
    print(f"   输入数据: {list(inputs.keys())}")
    
    # ... 原有逻辑
    
    print(f"   输出数据: {list(output.keys()) if isinstance(output, dict) else '单值'}")
    return output
```

### 3. 性能分析

#### 测量节点执行时间
```python
import time

def execute_node(node_id, node_data, context, edges):
    start_time = time.time()
    
    # ... 原有执行逻辑
    
    end_time = time.time()
    execution_time = end_time - start_time
    
    if execution_time > 0.1:  # 警告慢节点
        print(f"⚠️ 慢节点警告: {node_id} 耗时 {execution_time:.3f}s")
    
    return output
```

## 📚 最佳实践

### 1. 节点设计原则

#### ✅ 单一职责
每个节点只做一件事，比如：
- 线性变换 → 单独一个节点
- 激活函数 → 单独一个节点
- 数据形状变换 → 单独一个节点

#### ✅ 可组合性
设计节点时考虑如何与其他节点组合：
```python
# 好的设计 - 可以灵活组合
linear_out = linear_layer(x)
activated = relu_activation(linear_out)
dropouted = dropout_layer(activated)
```

#### ✅ 参数合理性
参数命名要清晰，默认值要合理：
```python
@node(id="dropout", label="Dropout", inputs=["x"], outputs=["out"],
      params={"p": 0.5})  # p=0.5是合理的默认值
def dropout_node():
    # ... 实现
```

### 2. 错误处理策略

#### 输入验证
```python
def compute(x, layer):
    # 验证输入存在
    if x is None:
        raise ValueError("输入数据不能为空")
    
    # 验证输入类型
    if not isinstance(x, torch.Tensor):
        raise TypeError(f"期望torch.Tensor，得到{type(x)}")
    
    # 验证输入形状
    if len(x.shape) != 2:
        raise ValueError(f"期望2D张量，得到形状{x.shape}")
    
    return layer(x)
```

#### 参数验证
```python
def build(input_shapes, params):
    # 参数范围验证
    dropout_rate = params.get("p", 0.5)
    if not 0 <= dropout_rate <= 1:
        raise ValueError(f"dropout率必须在[0,1]范围内，得到{dropout_rate}")
    
    # 参数类型验证
    hidden_size = params.get("hidden_size", 128)
    if not isinstance(hidden_size, int) or hidden_size <= 0:
        raise ValueError(f"隐藏层大小必须是正整数，得到{hidden_size}")
    
    return torch.nn.Dropout(dropout_rate)
```

### 3. 文档和注释

#### 节点文档
```python
@node(id="attention", label="注意力层", inputs=["query", "key", "value"], outputs=["out"],
      params={"embed_dim": 512, "num_heads": 8})
def attention_layer():
    """
    多头注意力层
    
    实现Transformer中的多头注意力机制。
    
    输入:
        query: 查询张量，形状 [batch, seq_len, embed_dim]
        key: 键张量，形状 [batch, seq_len, embed_dim]  
        value: 值张量，形状 [batch, seq_len, embed_dim]
    
    输出:
        out: 注意力输出，形状 [batch, seq_len, embed_dim]
        
    参数:
        embed_dim: 嵌入维度，必须是num_heads的倍数
        num_heads: 注意力头数
        
    示例:
        # 自注意力
        output = attention_layer(query=x, key=x, value=x)
        
        # 交叉注意力  
        output = attention_layer(query=x, key=y, value=y)
    """
    # ... 实现
```

## 🎯 总结

### 核心要点
1. **理解执行流程**：蓝图 → 拓扑排序 → 节点执行 → 结果收集
2. **掌握三元组**：infer（形状推断）→ build（层构建）→ compute（计算执行）
3. **注意数据流**：输入收集 → 计算处理 → 输出格式化
4. **重视错误处理**：输入验证 → 参数检查 → 异常处理

### 开发建议
1. **从小做起**：先实现简单的节点，逐步增加复杂度
2. **充分测试**：每个节点都要有测试用例，验证各种输入情况
3. **注重文档**：写好文档和注释，方便自己和他人理解
4. **保持简洁**：代码要清晰易读，避免过度优化影响可读性

### 学习路径
1. **阅读基础节点**：先看懂`nodes/base.py`中的简单节点
2. **理解执行流程**：跟踪`engine.py`的执行过程
3. **尝试简单修改**：修改现有节点的参数或逻辑
4. **开发新节点**：按照模板开发自己的节点
5. **构建复杂蓝图**：组合多个节点构建完整的神经网络

记住：**代码是写给人看的，机器只是顺便执行**。保持代码清晰易懂，比炫技更重要！