节点定义
	变换
		Linear
			输入乘权重加偏置，最基础的全连接
		Bilinear
			两组输入交叉相乘，建模交互关系
	激活
		ReLU
			负数归零，正数不变
		Sigmoid
			压缩到0~1，常用于门控开关
		Tanh
			压缩到-1~1，中心对称
		Softmax
			变成概率分布，加起来等于1
		Softplus
			ReLU的平滑版，永远为正
	归一化
		LayerNorm
			单样本特征维度归一化
		GroupNorm
			特征分组，组内归一化
	运算
		add
			逐元素加法，残差连接核心
		sub
			逐元素减法
		mul
			逐元素乘法，门控机制核心
		div
			逐元素除法
		matmul
			矩阵乘法，神经网络最核心运算
		bmm
			批量矩阵乘法，多头并行计算
		einsum
			字符串公式描述任意张量运算
		lerp
			线性插值
		dot
			向量点积，衡量相似度
		pow
			幂运算
		norm
			计算范数即向量长度
		exp
			e的x次方，Softmax内部用
		sqrt
			开平方
		sum
			沿指定维度求和
	形状
		reshape
			改变形状，如拆分多头
		view
			改变形状，要求内存连续
		transpose
			交换两个维度
		permute
			任意重排所有维度顺序
		squeeze
			去掉大小为1的维度
		unsqueeze
			增加一个大小为1的维度
		flatten
			多个维度压成一个
		unflatten
			一个维度展开成多个
		pad
			边缘填充值，序列对齐用
		detach
			切断梯度传播
		clone
			深拷贝，独立副本